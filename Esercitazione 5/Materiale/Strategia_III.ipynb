{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOin8SqzzFL4QxeU6C3djsj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RWtryEkbkLH","executionInfo":{"status":"ok","timestamp":1734536589185,"user_tz":-60,"elapsed":4845,"user":{"displayName":"LUKASZ GAJEWSKI","userId":"00258596529780099121"}},"outputId":"d52940b7-e46d-456d-b71f-807ccba5bbf4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n","Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmpadhahyh8\".\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include<assert.h>\n","#include<stdio.h>\n","#include<cuda.h>\n","#include<time.h>\n","\n","void prodottoCPU(float *a, float *b, float *c, int n);\n","__global__ void prodottoGPU(float* a, float* b, float* c, float* u, int n);\n","\n","int main(void) {\n","\tfloat *a_h, *b_h, *c_h, *c_h2; // host data\n","\tfloat *a_d, *b_d, *c_d; // device data\n","\tfloat *u_d, *u_h;\n","\tint N, nBytes, nBlockBytes, s_size;\n","\tdim3 gridDim, blockDim;\n","\tfloat elapsed_gpu, elapsed_cpu;\n","\tcudaEvent_t start_gpu, stop_gpu, start_cpu, stop_cpu;\n","\n","  N = 320000;\n","  blockDim.x = 32;\n","\n","\t// Determinazione esatta del numero di blocchi\n","\tgridDim= N / blockDim.x + ((N%blockDim.x) == 0 ? 0 : 1);\n","\n","\tnBytes = N*sizeof(float);\n","\tnBlockBytes = gridDim.x * sizeof(float);\n","\ta_h = (float*)malloc(nBytes);\n","\tb_h = (float*)malloc(nBytes);\n","\tc_h = (float*)malloc(nBytes);\n","\tc_h2 = (float*)malloc(nBytes);\n","\tu_h = (float*)malloc(nBlockBytes);\n","\tcudaMalloc((void **) &a_d, nBytes);\n","\tcudaMalloc((void **) &b_d, nBytes);\n","\tcudaMalloc((void **) &c_d, nBytes);\n","\tcudaMalloc((void **) &u_d, nBlockBytes);\n","\n","\t// Inizializzo i dati\n","\t// Inizializza la generazione random dei vettori utilizzando l'ora attuale del sistema\n","\tsrand((unsigned int) time(0));\n","\n","\tfor (int i = 0; i < N; i++) {\n","\t\ta_h[i] = rand()%5-2;\n","\t\tb_h[i] = rand()%5-2;;\n","\t}\n","\n","\tcudaMemcpy(a_d, a_h, nBytes, cudaMemcpyHostToDevice);\n","\tcudaMemcpy(b_d, b_h, nBytes, cudaMemcpyHostToDevice);\n","\n","\n","\t//azzeriamo il contenuto del vettore c\n","\tmemset(c_h, 0, nBytes);\n","\tcudaMemset(c_d, 0, nBytes);\n","\n","\ts_size = blockDim.x * sizeof(float);\n","\n","\t//invocazione del kernel\n","\tcudaEventCreate(&start_gpu);\n","\tcudaEventCreate(&stop_gpu);\n","\tcudaEventRecord(start_gpu);\n","\tprodottoGPU<<<gridDim, blockDim, s_size>>>(a_d, b_d, c_d, u_d, N);\n","\tcudaMemcpy(u_h, u_d, nBlockBytes, cudaMemcpyDeviceToHost);\n","\tfloat sommaGPU = 0;\n","\tfor(int i = 0; i < gridDim.x; i++){\n","\t\tsommaGPU+=u_h[i];\n","\t}\n","\tcudaEventRecord(stop_gpu);\n","\tcudaEventSynchronize(stop_gpu);\n","\tcudaEventElapsedTime(&elapsed_gpu, start_gpu, stop_gpu);\n","\tcudaEventDestroy(start_gpu);\n","\tcudaEventDestroy(stop_gpu);\n","\n","\tcudaEventCreate(&start_cpu);\n","\tcudaEventCreate(&stop_cpu);\n","\tcudaEventRecord(start_cpu);\n","\t// calcolo somma seriale su CPU\n","\tprodottoCPU(a_h, b_h, c_h2, N);\n","\tfloat sommaCPU = 0;\n","\tfor(int i = 0; i < N; i++){\n","\t\tsommaCPU += c_h2[i];\n","\t}\n","\tcudaEventRecord(stop_cpu);\n","\tcudaEventSynchronize(stop_cpu);\n","\n","\tcudaEventElapsedTime(&elapsed_cpu, start_cpu, stop_cpu);\n","\tcudaEventDestroy(start_cpu);\n","\tcudaEventDestroy(stop_cpu);\n","\n","\tif (N<20) {\n","\t\tfor(int i = 0; i < N; i++)\n","\t\t\tprintf(\"a_h[%d]=%6.2f \",i, a_h[i]);\n","\t\tprintf(\"\\n\");\n","\t\tfor(int i = 0; i < N; i++)\n","\t\t\tprintf(\"b_h[%d]=%6.2f \",i, b_h[i]);\n","\t\tprintf(\"\\n\");\n","\t\tfor(int i = 0; i < gridDim.x; i++)\n","\t\t\tprintf(\"u_h[%d]=%6.2f \",i, u_h[i]);\n","\t\tprintf(\"\\n\");\n","\t}\n","\n","\tprintf(\"s_GPU = %6.2f\\n\", sommaGPU);\n","\tprintf(\"s_CPU = %6.2f\\n\", sommaCPU);\n","\tprintf(\"time_GPU = %f\\n\", elapsed_gpu);\n","\tprintf(\"time_CPU = %f\\n\", elapsed_cpu);\n","\tassert(sommaGPU == sommaCPU);\n","\n","\n","\tfree(a_h); free(b_h); free(c_h); free(c_h2); free(u_h);\n","\tcudaFree(a_d); cudaFree(b_d); cudaFree(c_d); cudaFree(u_d);\n","\treturn 0;\n","}\n","\n","//Seriale\n","void prodottoCPU(float *a, float *b, float *c, int n) {\n","\tfor(int i = 0; i < n; i++)\n","\t\tc[i] = a[i] * b[i];\n","}\n","\n","//Parallelo\n","__global__ void prodottoGPU(float* a, float * b, float* c, float* u, int n) {\n","\textern __shared__ float s[];\n","\tint index = threadIdx.x + blockIdx.x*blockDim.x;\n","\tif(index < n)\n","\t\ts[threadIdx.x] = a[index]*b[index];\n","\t__syncthreads();\n","\n","\t// somma da ricombinare\n","\tint dist = blockDim.x;\n","\n","\tfor(int k = dist / 2; k > 0; k >>= 1){\n","\t\tif(threadIdx.x < k){\n","\t\t\ts[threadIdx.x] = s[threadIdx.x] + s[threadIdx.x + k];\n","\t\t}\n","\t\t__syncthreads();\n","\t}\n","\n","\t// restituzione output\n","\tif(threadIdx.x == 0){\n","\t\tu[blockIdx.x] = s[0];\n","\t}\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdRAe4dHbkIG","executionInfo":{"status":"ok","timestamp":1734537051087,"user_tz":-60,"elapsed":1612,"user":{"displayName":"LUKASZ GAJEWSKI","userId":"00258596529780099121"}},"outputId":"347eb55d-2fbf-4857-d830-2222d765abb5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["s_GPU = 633.00\n","s_CPU = 633.00\n","time_GPU = 0.305824\n","time_CPU = 2.464768\n","\n"]}]}]}